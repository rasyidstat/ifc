---
title: "USAID's Intelligent Forecasting: Model Future Contraceptive Use"
author: "Rasyid Ridha"
output: 
  html_document:
    toc: true
    theme: simplex
    code_folding: hide
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE, 
  message = FALSE,
  fig.path = "figs/"
)
```

```{r library}
library(lubridate)
library(tidyverse)
library(hrbrthemes)
library(forcats)
library(plotly)
library(feather)
library(skimr)
library(GGally)
library(mrsq)
theme_set(theme_nunito())
```

```{r data-prep}
annual <- read_csv("data/raw/contraceptive_case_data_annual.csv")
monthly <- read_csv("data/raw/contraceptive_case_data_monthly.csv")
logistic <- read_csv("data/raw/contraceptive_logistics_data.csv")
location <- read_csv("data/raw/service_delivery_site_data.csv")
product <- read_csv("data/raw/product.csv")
subm <- read_csv("data/raw/submission_format.csv")

# Join logistic and location
logistic <- logistic %>% 
  left_join(
    location %>% 
      select(-site_region, -site_district)
  )

# Join logistic and product
logistic <- logistic %>% 
  left_join(product)
```

```{r data-checking, eval=FALSE, include=FALSE}
annual$district %>% n_distinct() # 113 districts
monthly$district %>% n_distinct() # 113 districts

# Different district name
# COCODY - BINGERVILLE	
annual %>% 
  count(district) %>% 
  anti_join(monthly %>% 
              count(district) %>% 
              select(-n))
# COCODY BINGERVILLE
monthly %>% 
  count(district) %>% 
  anti_join(annual %>% 
              count(district) %>% 
              select(-n))

# Location data join
location %>% 
  count(district = site_district) %>% 
  anti_join(annual %>% 
              mutate(district = case_when(district == "ABOBO EST" ~ "ABOBO-EST",
                                          district == "COCODY - BINGERVILLE" ~ "COCODY-BINGERVILLE",
                                          district %in% c("GAGNOA 1", "GAGNOA 2") ~ "GAGNOA",
                                          district %in% c("KORHOGO 1", "KORHOGO 2") ~ "KORHOGO",
                                          district == "KOUMASSI" ~ "KOUMASSI-PORT BOUET-VRIDI",
                                          district == "MBAHIAKRO" ~ "M'BAHIAKRO",
                                          district == "OUANGOLODOUGOU" ~ "OUANGOLO",
                                          district == "SAN-PEDRO" ~ "SAN PEDRO",
                                          district == "TOULEUPLEU" ~ "TOULEPLEU",
                                          district == "YOPOUGON-OUEST SONGON" ~ "YOPOUGON-OUEST-SONGON",
                                          TRUE ~ district)) %>% 
              count(district) %>% 
              select(-n))
annual %>% 
  count(district) %>% 
  anti_join(location %>% 
              count(district = site_district) %>% 
              select(-n))
```


## EDA

### How many sites and products?

From submission file, we get:

* There are 1052 sites x products (should be 1716 sites x products ?)
* There are 156 sites
* There are 11 products

From training data (logistics), we get:

* There are 1357 sites x products (which means that 305 have no prediction in the last Q4 2019)
* There are 156 sites
* There are 11 products

We have 45 observation from Jan 2016 to Sep 2019 (almost 4-year data)

<details><summary>Detail</summary>

```{r}
subm %>% 
  count(site_code, product_code) %>% 
  nrow()
```

```{r}
subm %>% 
  count(site_code) %>% 
  nrow()
```

```{r}
subm %>% 
  count(product_code) %>% 
  nrow()
```

```{r}
logistic %>% 
  count(site_code, product_code) %>% 
  nrow()
```

```{r}
logistic %>% 
  count(site_code) %>% 
  nrow()
```

```{r}
logistic %>% 
  count(product_code) %>% 
  nrow()
```

</details> 

### Overall trend

It always increases :)

```{r}
p <- logistic %>% 
  group_by(year, month) %>% 
  summarise(stock_initial = sum(stock_initial),
            stock_received = sum(stock_received),
            stock_ordered = sum(stock_ordered),
            stock_end = sum(stock_end),
            stock_distributed = sum(stock_distributed)) %>% 
  ungroup() %>% 
  mutate(dt = dmy(paste("1", month, year, sep = "-"))) %>% 
  select(-year, -month) %>% 
  gather(key, val, -dt) %>% 
  ggplot(aes(dt, val, color = key)) +
  geom_line()
ggplotly(p)
```

### Monthly Trend {.tabset}

#### Overall

```{r}
logistic %>% 
  group_by(year, month) %>% 
  summarise(stock_distributed = sum(stock_distributed)) %>% 
  ungroup() %>% 
  mutate(dt = dmy(paste("1", month, year, sep = "-"))) %>% 
  ggplot(aes(month, stock_distributed, group = month)) +
  geom_boxplot() +
  scale_x_continuous(breaks = 1:12)
```

#### Adjusted %

```{r}
logistic %>% 
  group_by(year, month) %>% 
  summarise(stock_distributed = sum(stock_distributed)) %>% 
  ungroup() %>% 
  mutate(dt = dmy(paste("1", month, year, sep = "-"))) %>% 
  # filter(year != 2019) %>% 
  group_by(year) %>% 
  mutate(day_in_month = days_in_month(dt),
         stock_distributed_norm = stock_distributed / day_in_month * 30,
         pct = stock_distributed_norm / sum(stock_distributed_norm)) %>% 
  ungroup() %>% 
  ggplot(aes(month, pct, group = month)) +
  geom_boxplot() +
  scale_x_continuous(breaks = 1:12) +
  scale_y_continuous(labels = scales::percent)
```

#### Adjusted % (Exclude 2019)

```{r}
logistic %>% 
  group_by(year, month) %>% 
  summarise(stock_distributed = sum(stock_distributed)) %>% 
  ungroup() %>% 
  mutate(dt = dmy(paste("1", month, year, sep = "-"))) %>% 
  filter(year != 2019) %>%
  group_by(year) %>% 
  mutate(day_in_month = days_in_month(dt),
         stock_distributed_norm = stock_distributed / day_in_month * 30,
         pct = stock_distributed_norm / sum(stock_distributed_norm)) %>% 
  ungroup() %>% 
  ggplot(aes(month, pct, group = month)) +
  geom_boxplot() +
  scale_x_continuous(breaks = 1:12) +
  scale_y_continuous(labels = scales::percent)
```

### Quarterly Trend {.tabset}

```{r}
logistic %>% 
  group_by(year, month) %>% 
  summarise(stock_distributed = sum(stock_distributed)) %>% 
  ungroup() %>% 
  mutate(q = month %% 3) %>%
  mutate(dt = dmy(paste("1", month, year, sep = "-"))) %>% 
  filter(year != 2019) %>%
  group_by(year) %>% 
  mutate(day_in_month = days_in_month(dt),
         stock_distributed_norm = stock_distributed / day_in_month * 30,
         pct = stock_distributed_norm / sum(stock_distributed_norm)) %>% 
  ungroup() %>% 
  ggplot(aes(q, pct, group = q)) +
  geom_boxplot() +
  scale_x_continuous(breaks = 1:12) +
  scale_y_continuous(labels = scales::percent)
```

### Product {.tabset}

We have 11 products to explore!

#### All-in-one

```{r}
p <- logistic %>% 
  group_by(year, month, product_code) %>% 
  summarise(stock_distributed = sum(stock_distributed)) %>% 
  ungroup() %>% 
  mutate(dt = dmy(paste("1", month, year, sep = "-"))) %>% 
  left_join(product) %>% 
  ggplot(aes(dt, stock_distributed, 
             color = product_code,
             text = paste0('product_type: ', product_type))) +
  geom_line()
ggplotly(p)
```

#### Split

```{r}
p <- logistic %>% 
  group_by(year, month, product_code) %>% 
  summarise(stock_distributed = sum(stock_distributed)) %>% 
  ungroup() %>% 
  mutate(dt = dmy(paste("1", month, year, sep = "-"))) %>% 
  left_join(product) %>% 
  ggplot(aes(dt, stock_distributed, 
             color = product_code,
             text = paste0('product_type: ', product_type))) +
  geom_line() +
  facet_wrap(~product_code, scales = "free")
ggplotly(p)
```

### Spatial Data

```{r}
logistic %>% 
  group_by(site_code, site_longitude, site_latitude) %>% 
  summarise(stock_distributed = sum(stock_distributed)) %>% 
  ungroup() %>% 
  ggplot(aes(site_longitude, site_latitude, size = stock_distributed)) +
  geom_point(alpha = 0.7) +
  theme(panel.grid = element_blank(),
        legend.position = "bottom",
        axis.text = element_blank(), 
        axis.title = element_blank()) +
  coord_cartesian()
```

## Deeper EDA

```{r}
df_clean <- read_feather("data/clean/ifc_clean.feather")
df_summary <- df_clean %>% 
  group_by(site_code, product_code) %>% 
  summarise(cnt = n(),
            na_cnt = sum(isna),
            zero_cnt = sum(ifelse(stock_distributed == 0, 1, 0), na.rm = TRUE),
            zero_na_cnt = na_cnt + zero_cnt,
            first_date_no_na = ds[which.min(ifelse(!is.na(stock_distributed), stock_distributed, NA))],
            first_date_no_zero =  ds[which.min(ifelse(stock_distributed != 0, stock_distributed, NA))],
            cnt_v2_no_na = interval(first_date_no_na, ymd(20191001)) %/% months(1),
            cnt_v3_no_zero = interval(first_date_no_zero, ymd(20191001)) %/% months(1),
            val_sum = sum(stock_distributed, na.rm = TRUE),
            val_mean = mean(stock_distributed, na.rm = TRUE),
            val_median = median(stock_distributed, na.rm = TRUE),
            val_min = min(stock_distributed, na.rm = TRUE),
            val_max = max(stock_distributed, na.rm = TRUE),
            val_sd = sd(stock_distributed, na.rm = TRUE),
            val_m1 = mean(ifelse(month(ds) == 1, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m2 = mean(ifelse(month(ds) == 2, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m3 = mean(ifelse(month(ds) == 3, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m4 = mean(ifelse(month(ds) == 4, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m5 = mean(ifelse(month(ds) == 5, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m6 = mean(ifelse(month(ds) == 6, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m7 = mean(ifelse(month(ds) == 7, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m8 = mean(ifelse(month(ds) == 8, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m9 = mean(ifelse(month(ds) == 9, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m10 = mean(ifelse(month(ds) == 10, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m11 = mean(ifelse(month(ds) == 11, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            val_m12 = mean(ifelse(month(ds) == 12, stock_distributed, NA_real_), na.rm = TRUE) / val_mean,
            upper_outlier_cnt = sum(ifelse(stock_distributed >= val_mean + 2.5 * val_sd, 1, 0), na.rm = TRUE),
            lower_outlier_cnt = sum(ifelse(stock_distributed <= val_mean - 2.5 * val_sd, 1, 0), na.rm = TRUE),
            upper_outlier_cnt_2 = sum(ifelse(stock_distributed >= val_mean + 2 * val_sd, 1, 0), na.rm = TRUE),
            lower_outlier_cnt_2 = sum(ifelse(stock_distributed <= val_mean - 2 * val_sd, 1, 0), na.rm = TRUE)) %>% 
  ungroup()
```


```{r eval=FALSE, include=FALSE}
df_clean %>% 
  filter(site_code == "C1082",
         product_code == "AS21126") %>% 
  View()
df_clean %>% 
  filter(site_code == "C4022",
         product_code == "AS21126") %>% 
  View()
```

### Correlation {.tabset}

#### All

```{r}
df_clean %>% 
  select(contains("stock")) %>% 
  ggcorr(label = TRUE, label_round = 2)
```

#### t-1

```{r}
df_clean %>% 
  group_by(site_code, product_code) %>% 
  mutate_at(vars(contains("stock")), funs(l1 = lag(., 1))) %>% 
  ungroup() %>% 
  select(contains("l1"), stock_distributed) %>% 
  ggcorr(label = TRUE, label_round = 2)
```

#### t-2

```{r}
df_clean %>% 
  group_by(site_code, product_code) %>% 
  mutate_at(vars(contains("stock")), funs(l2 = lag(., 1))) %>% 
  ungroup() %>% 
  select(contains("l2"), stock_distributed) %>% 
  ggcorr(label = TRUE, label_round = 2)
```

#### t-3

```{r}
df_clean %>% 
  group_by(site_code, product_code) %>% 
  mutate_at(vars(contains("stock")), funs(l3 = lag(., 1))) %>% 
  ungroup() %>% 
  select(contains("l3"), stock_distributed) %>% 
  ggcorr(label = TRUE, label_round = 2)
```

#### t-4

```{r}
df_clean %>% 
  group_by(site_code, product_code) %>% 
  mutate_at(vars(contains("stock")), funs(l4 = lag(., 1))) %>% 
  ungroup() %>% 
  select(contains("l4"), stock_distributed) %>% 
  ggcorr(label = TRUE, label_round = 2)
```

### Zero Values

Most of series data have zero values

```{r}
df_summary %>% 
  mutate(is_zero = ifelse(zero_na_cnt == 0, FALSE, TRUE)) %>% 
  count(is_zero) %>% 
  mutate(p = n / sum(n))
```

### Data Summary

```{r describe}
df_summary %>%
  skim() %>% 
  filter(type %in% c("integer", "numeric"),
         stat != "complete") %>%
  select(variable, stat, formatted) %>%
  spread(key = stat, value = formatted) %>%
  select(variable,
         min = p0, p25, median = p50, mean, p75, max = p100, sd, missing,
         hist)
```

```{r dist}
df_summary %>%
  mutate(id = paste0(site_code, product_code)) %>% 
  select(id, na_cnt, zero_cnt, zero_na_cnt, val_mean, val_sd, 
         upper_outlier_cnt, val_min, val_max) %>%
  gather(key, val, -id) %>%
  ggplot(aes(val)) +
  geom_histogram() +
  facet_wrap(~key, nrow = 3, scales = "free")
```

### First Date Non-NA / Non-Zero {.tabset}

#### Non-NA (Monthly)

```{r}
df_summary %>% 
  count(first_date_no_na) %>% 
  ggplot(aes(first_date_no_na, n)) +
  geom_col()
```

#### Non-NA (Yearly)

```{r}
df_summary %>% 
  count(first_date_no_na = year(first_date_no_na)) %>% 
  mutate(p = n / sum(n)) %>% 
  ggplot(aes(first_date_no_na, n)) +
  geom_text(aes(label = scales::percent(p)), 
            vjust = -0.5,
            color = "blue",
            family = "Nunito") + 
  geom_col()
```

#### Non-Zero (Monthly)

```{r}
df_summary %>% 
  count(first_date_no_zero) %>% 
  ggplot(aes(first_date_no_zero, n)) +
  geom_col()
```

#### Non-Zero (Yearly)

```{r}
df_summary %>% 
  count(first_date_no_zero = year(first_date_no_zero)) %>% 
  mutate(p = n / sum(n)) %>% 
  ggplot(aes(first_date_no_zero, n)) +
  geom_text(aes(label = scales::percent(p)), 
            vjust = -0.5,
            color = "blue",
            family = "Nunito") + 
  geom_col()
```

### Time Series Check {.tabset}

#### Top

```{r}
df_summary %>% 
  arrange(desc(val_sum)) %>% 
  head(9) %>% 
  mutate(id = paste0("(", row_number(), ") ", 
                     site_code, "-", product_code)) %>% 
  inner_join(df_clean) %>% 
  ungroup() %>% 
  mutate(id = paste0(id, "\n", product_type)) %>% 
  ggplot(aes(ds, stock_distributed)) +
  geom_line() +
  facet_wrap(~id)
```

#### High Variance

```{r}
df_summary %>% 
  mutate(val_sd_mean = val_sd / val_mean) %>% 
  arrange(desc(val_sd)) %>% 
  head(9) %>% 
  mutate(id = paste0("(", row_number(), ") ", 
                     site_code, "-", product_code)) %>% 
  inner_join(df_clean) %>% 
  ungroup() %>% 
  mutate(id = paste0(id, "\n", product_type)) %>% 
  ggplot(aes(ds, stock_distributed)) +
  geom_line() +
  facet_wrap(~id)
```

#### Low Variance

```{r}
df_summary %>% 
  mutate(val_sd_mean = val_sd / val_mean) %>% 
  arrange(val_sd) %>% 
  head(9) %>% 
  mutate(id = paste0("(", row_number(), ") ", 
                     site_code, "-", product_code)) %>% 
  inner_join(df_clean) %>% 
  ungroup() %>% 
  mutate(id = paste0(id, "\n", product_type)) %>% 
  ggplot(aes(ds, stock_distributed)) +
  geom_line() +
  facet_wrap(~id)
```

#### High Outlier

```{r}
df_summary %>% 
  arrange(desc(upper_outlier_cnt)) %>% 
  head(9) %>% 
  mutate(id = paste0("(", row_number(), ") ", 
                     site_code, "-", product_code)) %>% 
  inner_join(df_clean) %>% 
  ungroup() %>% 
  mutate(id = paste0(id, "\n", product_type)) %>% 
  ggplot(aes(ds, stock_distributed)) +
  geom_line() +
  facet_wrap(~id)
```

## External Data

Look on external data, can we utilize it to make better decision

* Population on the region (growth)
* Fertility rate, birth rate during specific period
* Spatial data
* Weather
