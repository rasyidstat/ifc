{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission 1\n",
    "\n",
    "Average ensemble of all LightGBM model from different seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Utility\n",
    "from itertools import combinations\n",
    "from itertools import product\n",
    "import random\n",
    "import calendar\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "TARGET = 'stock_distributed'\n",
    "SEED = 2020\n",
    "categorical_features = ['site_code',\n",
    "                        'product_code',\n",
    "                        'region',\n",
    "                        'district',\n",
    "                        'site_type',\n",
    "                        'product_type']\n",
    "remove_features = ['stock_initial', 'stock_received', 'stock_adjustment', 'stock_distributed',\n",
    "                   'stock_end', 'average_monthly_consumption', 'stock_stockout_days',\n",
    "                   'stock_ordered', 'ds', 'isna', 'idx', 'product_name']\n",
    "numerical_features = ['stock_initial', 'stock_received', 'stock_adjustment', 'stock_distributed',\n",
    "                      'stock_end', 'average_monthly_consumption', 'stock_ordered']\n",
    "\n",
    "\n",
    "# Utility\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "\n",
    "# Main functions\n",
    "def process_data(features = [TARGET], test_block = 43, lag = [1,2,3,4]):\n",
    "    '''\n",
    "    Process data for main features engineering\n",
    "    '''\n",
    "    df = _read_data(features = features)\n",
    "    df = _generate_test_set(df)\n",
    "    df = _get_cumulative_nonzero(df)\n",
    "    df = generate_lag_features(df, lag = lag, features = features)\n",
    "    return df\n",
    "\n",
    "def get_mase_constant_agg(test_block = [46,43,40,37,34]):\n",
    "    '''\n",
    "    Generate MASE constant (denominator) for each CV block\n",
    "    '''\n",
    "    df = _read_data()\n",
    "    df = _get_cumulative_nonzero(df)\n",
    "    summary_block = pd.DataFrame({})\n",
    "    for block in test_block:\n",
    "        df_block = _get_mase_constant(df, block)\n",
    "        df_block = df[['site_code','product_code','mase_constant']].drop_duplicates()\n",
    "        df_block = pd.concat([df_block.assign(idx = block),\n",
    "                              df_block.assign(idx = block + 1),\n",
    "                              df_block.assign(idx = block + 2)])\n",
    "        summary_block = summary_block.append(df_block)\n",
    "    summary_block = summary_block.sort_values(by = ['site_code','product_code','idx']).reset_index(drop=True)\n",
    "    return summary_block\n",
    "\n",
    "def process_train_cv(df, verbose = 500, is_print = False,\n",
    "                     use_log = False, use_weight = False,\n",
    "                     remove_first_na = False, remove_first_zero = False,\n",
    "                     cv_block = [43,40,37,34], full_train = True,\n",
    "                     version = 0,\n",
    "                     use_separate_model = False,\n",
    "                     use_id = False,\n",
    "                     use_diff = False,\n",
    "                     use_weekend = False,\n",
    "                     use_month = False,\n",
    "                     use_quarter = False,\n",
    "                     use_year = False):\n",
    "    \n",
    "    if use_id:\n",
    "        df = generate_id(df)\n",
    "    if use_diff:\n",
    "        df = generate_diff_features(df)\n",
    "    if use_weekend:\n",
    "        df = get_weekend_in_month(df, use_percentage=True)\n",
    "    if use_month:\n",
    "        df = generate_date_features(df, use_month=True)\n",
    "    if use_quarter:\n",
    "        df = generate_date_features(df, use_quarter=True, use_month=False)\n",
    "    if use_year:\n",
    "        df = generate_date_features(df, use_year=True, use_month=False)\n",
    "    \n",
    "    cv = []\n",
    "    cv_mae = []\n",
    "    cv_rmse = []\n",
    "    pred_overall = pd.DataFrame({})\n",
    "    if full_train:\n",
    "        cv_block = cv_block + [46]\n",
    "    \n",
    "    for test_block in cv_block:\n",
    "        mdl, pred = process_train(df.loc[:, ~df.columns.str.contains('lag_(1|2)', case=False)], \n",
    "                                  test_block = test_block, verbose = verbose, is_print = is_print,\n",
    "                                  use_log = use_log, use_weight = use_weight,\n",
    "                                  remove_first_na = remove_first_na, remove_first_zero = remove_first_zero)\n",
    "        if use_separate_model:\n",
    "            lgb_params.update({'lambda_l2': 0.1})\n",
    "            mdl2, pred2 = process_train(df.loc[:, ~df.columns.str.contains('lag_1', case=False)], \n",
    "                                        test_block = test_block, verbose = verbose, is_print = is_print,\n",
    "                                        use_log = use_log, use_weight = use_weight,\n",
    "                                        remove_first_na = remove_first_na, remove_first_zero = remove_first_zero)\n",
    "            mdl3, pred3 = process_train(df,\n",
    "                                        test_block = test_block, verbose = verbose, is_print = is_print,\n",
    "                                        use_log = use_log, use_weight = use_weight,\n",
    "                                        remove_first_na = remove_first_na, remove_first_zero = remove_first_zero)\n",
    "            pred = pd.concat([pred[pred['idx'] == test_block+2], \n",
    "                              pred2[pred2['idx'] == test_block+1],\n",
    "                              pred3[pred3['idx'] == test_block]], axis=0)\n",
    "            pred['block'] = test_block\n",
    "        \n",
    "        pred_overall = pred_overall.append(pred, ignore_index=True)\n",
    "        if test_block <= 43:\n",
    "            cv.append(mase_df(pred))\n",
    "            cv_mae.append(mae(pred.stock_distributed, np.where(pred.preds < 0, 0, pred.preds)))\n",
    "            cv_rmse.append(rmse(pred.stock_distributed, np.where(pred.preds < 0, 0, pred.preds)))\n",
    "    \n",
    "    print('CV details is {}'.format([round(val, 4) for val in cv]))\n",
    "    print('CV-1 is {:.4f}, CV mean is {:.4f} and CV std is {:.4f}'.format(cv[0], np.array(cv).mean(), np.array(cv).std()))\n",
    "    \n",
    "    print('MASE-CV details is {}'.format([round(val, 4) for val in cv_mae]))\n",
    "    print('MASE-CV-1 is {:.4f}, mean is {:.4f} and std is {:.4f}'.format(cv_mae[0], np.array(cv_mae).mean(), np.array(cv_mae).std()))\n",
    "    \n",
    "    \n",
    "    if use_separate_model:\n",
    "        m = 'individual'\n",
    "    else:\n",
    "        m = 'base'\n",
    "    version = str(version)\n",
    "    \n",
    "    pred_overall.to_csv(f'data/temp/lgb_v{version}_{m}_pred.csv', index=False)\n",
    "    return pred_overall\n",
    "\n",
    "\n",
    "# Features Engineering\n",
    "def _read_data(features = [TARGET]):\n",
    "    df = pd.read_csv('data/ifc_clean.csv')\n",
    "    df[features] = df[features].fillna(0)\n",
    "    print('Read data, data frame size: {}'.format(df.shape))\n",
    "    return df\n",
    "\n",
    "def _generate_test_set(df):\n",
    "    df_test = pd.DataFrame({})\n",
    "    for i, dt in enumerate(['2019-10-01','2019-11-01','2019-12-01']):\n",
    "        test_set = df[df['idx'] == 45].reset_index(drop=True)\n",
    "        test_set['idx'] = test_set['idx'] + i + 1\n",
    "        test_set['ds'] = dt\n",
    "        test_set[['stock_initial','stock_received','stock_distributed',\n",
    "                  'stock_adjustment','stock_end','average_monthly_consumption',\n",
    "                  'stock_stockout_days','stock_ordered']] = np.inf\n",
    "        df_test = df_test.append(test_set)\n",
    "    df = df.append(df_test).sort_values(by = ['site_code','product_code','idx']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def _get_cumulative_nonzero(df):\n",
    "    '''\n",
    "    This function needs to be used before any data removal \n",
    "    because of lagging or rolling features.\n",
    "    Exclude first NA or zero data by df.loc[df['isna_int'] > 0] or df.loc[df['iszero_int'] > 0].shape\n",
    "    '''\n",
    "    df['isna_int'] = [0 if x == True else 1 for x in df['isna']]\n",
    "    df['iszero_int'] = [0 if x == 0 else 1 for x in df['stock_distributed']]\n",
    "    df[['isna_int', 'iszero_int']] = df.groupby(['site_code', 'product_code'])[['isna_int', 'iszero_int']].transform(lambda x: x.cumsum())\n",
    "    print('Get cumulative nonzero flag')\n",
    "    return df\n",
    "\n",
    "def _get_mase_constant(df, test_block = 46, remove_first_na = True, remove_first_zero = False):\n",
    "    '''\n",
    "    This function needs to be used by applying `get_cumulative_nonzero` \n",
    "    to exclude first NA or zero data.\n",
    "    It also needs to be used before any data removal\n",
    "    The default test_block is 46 ( data) which will be used as the  (43 for latest CV)\n",
    "    constant of the mase denominator for each series.\n",
    "    In default, remove first NA data from the training set\n",
    "    '''\n",
    "    df['diff_abs'] = df.loc[(df['isna_int'] > 0) & (df['idx'] < test_block)].groupby(['site_code', 'product_code'])['stock_distributed'].transform(lambda x: abs(x-x.shift(1)))\n",
    "    df['mase_constant'] = df.groupby(['site_code', 'product_code'])['diff_abs'].transform(lambda x: x.mean())\n",
    "    df['mase_constant'] = 1 / df['mase_constant']\n",
    "    df['mase_constant'] = df['mase_constant'].replace(np.inf, 0).replace(np.nan, 0)\n",
    "    print('Get MASE constant')\n",
    "    return df\n",
    "\n",
    "def generate_lag_features(df, lag = [3,4], features = [TARGET]):\n",
    "    df = df.assign(**{\n",
    "            '{}_lag_{}'.format(col, l): df.groupby(['site_code', 'product_code'])[col].transform(lambda x: x.shift(l))\n",
    "            for l in lag\n",
    "            for col in features\n",
    "         })\n",
    "    lag_features = [col for col in df.columns if 'lag' in col]\n",
    "    df = df.dropna(subset = lag_features)\n",
    "    print('Generate lag features {}, data frame size: {}'.format(lag, df.shape))\n",
    "    return df \n",
    "\n",
    "def generate_diff_features(df, minus = True, ratio = False):\n",
    "    lag_features = [col for col in df.columns if 'lag' in col]\n",
    "    for i,j in combinations(lag_features, 2):\n",
    "        if minus:\n",
    "            df['{}_minus_{}'.format(i, j)] = df[i] - df[j]\n",
    "        if ratio:\n",
    "            df['{}_div_{}'.format(i, j)] = (df[i] / df[j]).fillna(0)\n",
    "    print('Generate diff features')\n",
    "    return df\n",
    "\n",
    "def generate_id(df):\n",
    "    df['id'] = df['site_code'] + '-' + df['product_code']\n",
    "    df['id'] = df['id'].astype('category')\n",
    "    print('Generate ID features')\n",
    "    return df\n",
    "\n",
    "def generate_date_features(df, use_month = True, use_quarter = False, use_year = False, use_category = True):\n",
    "    '''\n",
    "    Generate date features as category or integer, consists of:\n",
    "    month, quarter and year\n",
    "    '''\n",
    "    if use_month:\n",
    "        df['month'] = pd.to_datetime(df['ds']).dt.month\n",
    "    if use_quarter:\n",
    "        df['quarter'] = pd.to_datetime(df['ds']).dt.quarter\n",
    "    if use_year:\n",
    "        df['year'] = pd.to_datetime(df['ds']).dt.year\n",
    "    date_features = df.filter(regex = '^(month|quarter|year)$').columns.tolist()\n",
    "    if use_category:\n",
    "        df[date_features] = df[date_features].astype('category')\n",
    "    print('Generate date features {}'.format(date_features))\n",
    "    return df\n",
    "\n",
    "def get_weekend_in_month(df, use_percentage = False):\n",
    "    df['weekend_in_month'] = pd.to_datetime(df['ds']).dt.days_in_month - np.busday_count(\n",
    "        pd.to_datetime(df['ds']).dt.date.values.astype('datetime64[D]'), \n",
    "        (pd.to_datetime(df['ds']).dt.date + pd.DateOffset(months=1)).values.astype('datetime64[D]') \n",
    "    )\n",
    "    if use_percentage:\n",
    "        df['weekend_in_month'] = df['weekend_in_month'] / pd.to_datetime(df['ds']).dt.days_in_month\n",
    "    print('Get number of weekend days in month')\n",
    "    return df\n",
    "\n",
    "def get_day_in_month(df):\n",
    "    df['day_in_month'] = pd.to_datetime(df['ds']).dt.daysinmonth\n",
    "    print('Get days in month')\n",
    "    return df\n",
    "\n",
    "def remove_unnecessary_columns(df, column_list = []):\n",
    "    '''\n",
    "    Remove columns generated from features engineering process outside of \n",
    "    list from `remove_features`\n",
    "    '''\n",
    "    column_list_all = ['diff_abs'] + column_list\n",
    "    column_list_selected = list(set(column_list_all) & set(df.columns.tolist()))\n",
    "    df = df.drop(column_list_selected, axis = 1)\n",
    "    print('Remove unnecessary columns')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Error function\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))\n",
    "\n",
    "def mae(y, y_pred):\n",
    "    return np.mean(np.abs(y - y_pred))\n",
    "\n",
    "def mase_df(pred_df, clip_lower = True):\n",
    "    pred_df = pd.merge(pred_df, summary_block[['site_code', 'product_code', 'idx', 'mase_constant']])\n",
    "    if clip_lower:\n",
    "        pred_df[['preds']] = pred_df[['preds']].clip(lower = 0)\n",
    "    pred_df['scaled_error'] = abs(pred_df['stock_distributed'] - pred_df['preds']) * pred_df['mase_constant']\n",
    "    mase = pred_df.groupby(['site_code', 'product_code'])['scaled_error'].agg(lambda x: x.mean()).mean()\n",
    "    return mase\n",
    "\n",
    "def mae_row(pred_df, clip_lower = True):\n",
    "    if clip_lower:\n",
    "        pred_df[['preds']] = pred_df[['preds']].clip(lower = 0)\n",
    "    return(mae(pred_df.preds, pred_df.stock_distributed))\n",
    "\n",
    "\n",
    "# Modeling\n",
    "def process_train(df, test_block = 43, verbose = 500, is_print = True,\n",
    "                  use_log = False, use_weight = False,\n",
    "                  remove_first_na = False, remove_first_zero = False,\n",
    "                  version = 0):\n",
    "    \n",
    "    df = df.copy()\n",
    "    local_params = lgb_params.copy()           \n",
    "        \n",
    "    if use_log:\n",
    "        df[TARGET] = np.log1p(df[TARGET])\n",
    "\n",
    "    # Categorical feature\n",
    "    for col in categorical_features:\n",
    "        try:\n",
    "            df[col] = df[col].astype('category')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Our features\n",
    "    remove_additional_features = ['isna_int', 'iszero_int', 'mase_constant', 'diff_abs']\n",
    "    remove_additional_features_selected = list(set(remove_additional_features) & set(df.columns.tolist()))\n",
    "    all_features = [col for col in list(df) if col not in (remove_features + remove_additional_features_selected)]\n",
    "    if is_print: print(all_features)\n",
    "        \n",
    "    # Check lag\n",
    "    if len([col for col in all_features if 'lag_1' in col]) > 0:\n",
    "        block_next = 1\n",
    "    elif len([col for col in all_features if 'lag_2' in col]) > 0:\n",
    "        block_next = 2\n",
    "    else:\n",
    "        block_next = 3\n",
    " \n",
    "    if remove_first_na:\n",
    "        train_mask = (df['idx']<test_block) & (df['isna_int']>0)\n",
    "    elif remove_first_zero:\n",
    "        train_mask = (df['idx']<test_block) & (df['iszero_int']>0)\n",
    "    else:\n",
    "        train_mask = df['idx']<test_block\n",
    "    valid_mask = (df['idx'].isin(range(test_block,test_block + block_next))) & (df['isna'] == False)\n",
    "    \n",
    "    if use_weight:\n",
    "        train_data = lgb.Dataset(df[train_mask][all_features], label=df[train_mask][TARGET], weight=df[train_mask]['mase_constant'])\n",
    "        valid_data = lgb.Dataset(df[valid_mask][all_features], label=df[valid_mask][TARGET], weight=df[valid_mask]['mase_constant'])\n",
    "    else:\n",
    "        train_data = lgb.Dataset(df[train_mask][all_features], label=df[train_mask][TARGET])\n",
    "        valid_data = lgb.Dataset(df[valid_mask][all_features], label=df[valid_mask][TARGET])\n",
    "    \n",
    "    print('Train data frame size: ({}, {})'.format(len(train_mask[train_mask]), len(all_features)))\n",
    "    print('Train time block', df[train_mask]['idx'].min(), df[train_mask]['idx'].max())\n",
    "    if is_print: \n",
    "        print('Valid time block', df[valid_mask]['idx'].min(), df[valid_mask]['idx'].max())\n",
    "\n",
    "    temp_df = df[valid_mask]\n",
    "    del df\n",
    "    seed_everything(SEED)\n",
    "    if test_block != 46:\n",
    "        estimator = lgb.train(local_params,\n",
    "                              train_data,\n",
    "                              valid_sets = [valid_data],\n",
    "                              verbose_eval = verbose) \n",
    "    else:\n",
    "        if 'early_stopping_rounds' in local_params: \n",
    "            del local_params['early_stopping_rounds']\n",
    "        estimator = lgb.train(local_params,\n",
    "                              train_data) \n",
    "        \n",
    "    temp_df['preds'] = estimator.predict(temp_df[all_features])\n",
    "    if use_log:\n",
    "        temp_df['preds'] = np.expm1(temp_df['preds'])\n",
    "        temp_df[TARGET] = np.expm1(temp_df[TARGET])\n",
    "    temp_df = temp_df[['site_code','product_code','idx',TARGET,'preds']]\n",
    "    if ('mase_constant' in remove_additional_features_selected) & (test_block != 46):\n",
    "        print('MASE is {}'.format(mase_df(temp_df)))\n",
    "    return estimator, temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data, data frame size: (61065, 20)\n",
      "Get cumulative nonzero flag\n",
      "Get MASE constant\n",
      "Get MASE constant\n",
      "Get MASE constant\n",
      "Get MASE constant\n",
      "Get MASE constant\n"
     ]
    }
   ],
   "source": [
    "summary_block = get_mase_constant_agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('data/temp/lgb_vallf_seed_1010_individual_pred.csv')\n",
    "sub2 = pd.read_csv('data/temp/lgb_vallf_seed_2020_individual_pred.csv')\n",
    "sub3 = pd.read_csv('data/temp/lgb_vallf_seed_3030_individual_pred.csv')\n",
    "sub4 = pd.read_csv('data/temp/lgb_vallf_seed_2020_diff_individual_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15283, 6, 15283, 6, 15283, 6, 15283, 6)\n"
     ]
    }
   ],
   "source": [
    "print(sub1.shape + sub2.shape + sub3.shape + sub4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = pd.concat([sub1, sub2, sub3, sub4])\n",
    "ensemble = ensemble.groupby(['site_code','product_code','idx','block']). \\\n",
    "                    agg({'stock_distributed': 'mean', 'preds': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mase_df_all(df, df_name):\n",
    "    print(df_name)\n",
    "    cv = []\n",
    "    for block in [43,40,37,34]:\n",
    "        cv_block = mase_df(df[df['block'] == block])\n",
    "        cv.append(cv_block)\n",
    "        print('{} is {}'.format(block, cv_block))\n",
    "    print('CV mean is {:.4f} and CV std is {:.4f}'.format(np.array(cv).mean(),\n",
    "                                                  np.array(cv).std()))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub1\n",
      "43 is 0.953607835360644\n",
      "40 is 1.1283544337221507\n",
      "37 is 1.0125291826310585\n",
      "34 is 1.030527234154662\n",
      "CV mean is 1.0313 and CV std is 0.0629\n",
      "\n",
      "Sub2\n",
      "43 is 0.9501340236798038\n",
      "40 is 1.1200935348767513\n",
      "37 is 1.0191419505120183\n",
      "34 is 1.034434855245385\n",
      "CV mean is 1.0310 and CV std is 0.0605\n",
      "\n",
      "Sub3\n",
      "43 is 0.9510601109013056\n",
      "40 is 1.1258603352701582\n",
      "37 is 1.0218130438506694\n",
      "34 is 1.042063623616868\n",
      "CV mean is 1.0352 and CV std is 0.0623\n",
      "\n",
      "Sub4\n",
      "43 is 0.9514541648746908\n",
      "40 is 1.1292668370966017\n",
      "37 is 1.0155813489643304\n",
      "34 is 1.022713989734268\n",
      "CV mean is 1.0298 and CV std is 0.0638\n",
      "\n",
      "Ensemble\n",
      "43 is 0.9476971101703721\n",
      "40 is 1.1227787003225915\n",
      "37 is 1.0142236437152379\n",
      "34 is 1.028210691748323\n",
      "CV mean is 1.0282 and CV std is 0.0625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mase_df_all(sub1, \"Sub1\")\n",
    "mase_df_all(sub2, \"Sub2\")\n",
    "mase_df_all(sub3, \"Sub3\")\n",
    "mase_df_all(sub4, \"Sub4\")\n",
    "mase_df_all(ensemble, \"Ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for threshold in [1,0.75,0.5,0.25, 0]:\n",
    "#     print(threshold)\n",
    "#     mase_df_all(sub1.assign(preds = factor*np.where(sub1['preds'] < threshold, 0, sub1['preds'])), \"Sub1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mase_df_all(sub1.assign(preds = np.round(np.where(sub1['preds'] < threshold, 0, sub1['preds']), 0)), \"Sub1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble using different seed can improve the score :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(sub, name):\n",
    "    # Main submission\n",
    "    sub = sub[sub['block'] == 46].copy()\n",
    "    sub['year'] = 2019\n",
    "    sub.loc[sub['idx'] == 46, 'month'] = 10\n",
    "    sub.loc[sub['idx'] == 47, 'month'] = 11\n",
    "    sub.loc[sub['idx'] == 48, 'month'] = 12\n",
    "    sub = sub.loc[:, ['year','month','site_code','product_code','preds']]\n",
    "    sub[['preds']] = sub[['preds']].clip(lower = 0)\n",
    "    \n",
    "    # If not found, use median value\n",
    "    sub_median = _read_data()\n",
    "    sub_median = sub_median[sub_median['isna'] == False]\n",
    "    sub_median = sub_median.groupby(['site_code','product_code']). \\\n",
    "                            agg({'stock_distributed': 'median'}).reset_index()\n",
    "    \n",
    "    # Join with sub_format.csv\n",
    "    sub_format = pd.read_csv('data/submission_format.csv')\n",
    "    sub_final = pd.merge(sub_format, sub, how='left')\n",
    "    sub_final = pd.merge(sub_final, sub_median, how='left')\n",
    "    \n",
    "    # Coalesce: main submission -> median -> 0\n",
    "    sub_final['predicted_value'] = sub_final[['preds','stock_distributed','predicted_value']]. \\\n",
    "                                   bfill(axis=1).iloc[:,0]\n",
    "    sub_final = sub_final.drop(columns = ['preds','stock_distributed'])\n",
    "    print('Generate submission')\n",
    "    sub_final.to_csv(name, index=False)\n",
    "    return sub_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data, data frame size: (61065, 20)\n",
      "Generate submission\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>site_code</th>\n",
       "      <th>product_code</th>\n",
       "      <th>predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27134</td>\n",
       "      <td>8.842204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27132</td>\n",
       "      <td>0.015848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27000</td>\n",
       "      <td>0.713116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27137</td>\n",
       "      <td>1.483440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27138</td>\n",
       "      <td>3.946439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27000</td>\n",
       "      <td>0.346894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27139</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27137</td>\n",
       "      <td>0.224984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27138</td>\n",
       "      <td>0.303299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27133</td>\n",
       "      <td>2.137900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3115 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month site_code product_code  predicted_value\n",
       "0     2019     10     C4001      AS27134         8.842204\n",
       "1     2019     10     C4001      AS27132         0.015848\n",
       "2     2019     10     C4001      AS27000         0.713116\n",
       "3     2019     10     C4001      AS27137         1.483440\n",
       "4     2019     10     C4001      AS27138         3.946439\n",
       "...    ...    ...       ...          ...              ...\n",
       "3110  2019     12     C5076      AS27000         0.346894\n",
       "3111  2019     12     C5076      AS27139         0.000000\n",
       "3112  2019     12     C5076      AS27137         0.224984\n",
       "3113  2019     12     C5076      AS27138         0.303299\n",
       "3114  2019     12     C5076      AS27133         2.137900\n",
       "\n",
       "[3115 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_submission(ensemble, 'submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
