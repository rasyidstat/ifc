{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Challenge link: https://competitions4dev.org/forecastingprize\n",
    "\n",
    "## Model Summary\n",
    "\n",
    "#### Add more postprocessing for model2 based on model1\n",
    "\n",
    "- Predictions below 0.75 are clipped to 0\n",
    "- Add multiplication factor 1.05, 1.1 and 1.15 for t+1, t+2, and t+3\n",
    "\n",
    "Average ensemble of six LightGBM models to predict `stock_distributed` for t+1, t+2, and t+3\n",
    "\n",
    "* Cross-validation: 4x time series CV\n",
    "  * Block 43: Jul-Sep 2019\n",
    "  * Block 40: Apr-Jun 2019\n",
    "  * Block 37: Jan-Mar 2019\n",
    "  * Block 34: Oct-Dec 2018\n",
    "* Features engineering\n",
    "  * Lag t-1, t-2, t-3, t-4\n",
    "  * Longitude, latitude\n",
    "  * Categorical features: product, region, type\n",
    "* Modeling\n",
    "  * Optimize MSE, not RMSE since the evaluationn metrics is MASE (MAE divided by a constant)\n",
    "  * Full training using 1000 rounds\n",
    "  * Learning rate is 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Utility\n",
    "from itertools import combinations, product\n",
    "import random\n",
    "import calendar\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "TARGET = 'stock_distributed'\n",
    "SEED = 2020\n",
    "categorical_features = ['site_code',\n",
    "                        'product_code',\n",
    "                        'region',\n",
    "                        'district',\n",
    "                        'site_type',\n",
    "                        'product_type']\n",
    "remove_features = ['stock_initial', 'stock_received', 'stock_adjustment', 'stock_distributed',\n",
    "                   'stock_end', 'average_monthly_consumption', 'stock_stockout_days',\n",
    "                   'stock_ordered', 'ds', 'isna', 'idx', 'product_name']\n",
    "numerical_features = ['stock_initial', 'stock_received', 'stock_adjustment', 'stock_distributed',\n",
    "                      'stock_end', 'average_monthly_consumption', 'stock_ordered']\n",
    "\n",
    "\n",
    "# Utility\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "\n",
    "# Main functions\n",
    "def process_data(features = [TARGET], test_block = 43, lag = [1,2,3,4]):\n",
    "    '''\n",
    "    Process data for main features engineering\n",
    "    '''\n",
    "    df = _read_data(features = features)\n",
    "    df = _generate_test_set(df)\n",
    "    df = _get_cumulative_nonzero(df)\n",
    "    df = generate_lag_features(df, lag = lag, features = features)\n",
    "    return df\n",
    "\n",
    "def get_mase_constant_agg(test_block = [46,43,40,37,34]):\n",
    "    '''\n",
    "    Generate MASE constant (denominator) for each CV block\n",
    "    '''\n",
    "    df = _read_data()\n",
    "    df = _get_cumulative_nonzero(df)\n",
    "    summary_block = pd.DataFrame({})\n",
    "    for block in test_block:\n",
    "        df_block = _get_mase_constant(df, block)\n",
    "        df_block = df[['site_code','product_code','mase_constant']].drop_duplicates()\n",
    "        df_block = pd.concat([df_block.assign(idx = block),\n",
    "                              df_block.assign(idx = block + 1),\n",
    "                              df_block.assign(idx = block + 2)])\n",
    "        summary_block = summary_block.append(df_block)\n",
    "    summary_block = summary_block.sort_values(by = ['site_code','product_code','idx']).reset_index(drop=True)\n",
    "    return summary_block\n",
    "\n",
    "def process_train_cv(df, verbose = 500, is_print = False,\n",
    "                     use_log = False, use_weight = False,\n",
    "                     remove_first_na = False, remove_first_zero = False,\n",
    "                     cv_block = [43,40,37,34], full_train = True,\n",
    "                     version = 0,\n",
    "                     use_separate_model = False,\n",
    "                     use_id = False,\n",
    "                     use_diff = False,\n",
    "                     use_weekend = False,\n",
    "                     use_month = False,\n",
    "                     use_quarter = False,\n",
    "                     use_year = False):\n",
    "    \n",
    "    if use_id:\n",
    "        df = generate_id(df)\n",
    "    if use_diff:\n",
    "        df = generate_diff_features(df)\n",
    "    if use_weekend:\n",
    "        df = get_weekend_in_month(df, use_percentage=True)\n",
    "    if use_month:\n",
    "        df = generate_date_features(df, use_month=True)\n",
    "    if use_quarter:\n",
    "        df = generate_date_features(df, use_quarter=True, use_month=False)\n",
    "    if use_year:\n",
    "        df = generate_date_features(df, use_year=True, use_month=False)\n",
    "    \n",
    "    cv = []\n",
    "    cv_mae = []\n",
    "    cv_rmse = []\n",
    "    pred_overall = pd.DataFrame({})\n",
    "    if full_train:\n",
    "        cv_block = cv_block + [46]\n",
    "    \n",
    "    for test_block in cv_block:\n",
    "        mdl, pred = process_train(df.loc[:, ~df.columns.str.contains('lag_(1|2)', case=False)], \n",
    "                                  test_block = test_block, verbose = verbose, is_print = is_print,\n",
    "                                  use_log = use_log, use_weight = use_weight,\n",
    "                                  remove_first_na = remove_first_na, remove_first_zero = remove_first_zero)\n",
    "        if use_separate_model:\n",
    "            lgb_params.update({'lambda_l2': 0.1})\n",
    "            mdl2, pred2 = process_train(df.loc[:, ~df.columns.str.contains('lag_1', case=False)], \n",
    "                                        test_block = test_block, verbose = verbose, is_print = is_print,\n",
    "                                        use_log = use_log, use_weight = use_weight,\n",
    "                                        remove_first_na = remove_first_na, remove_first_zero = remove_first_zero)\n",
    "            mdl3, pred3 = process_train(df,\n",
    "                                        test_block = test_block, verbose = verbose, is_print = is_print,\n",
    "                                        use_log = use_log, use_weight = use_weight,\n",
    "                                        remove_first_na = remove_first_na, remove_first_zero = remove_first_zero)\n",
    "            pred = pd.concat([pred[pred['idx'] == test_block+2], \n",
    "                              pred2[pred2['idx'] == test_block+1],\n",
    "                              pred3[pred3['idx'] == test_block]], axis=0)\n",
    "            pred['block'] = test_block\n",
    "        \n",
    "        pred_overall = pred_overall.append(pred, ignore_index=True)\n",
    "        if test_block <= 43:\n",
    "            cv.append(mase_df(pred))\n",
    "            cv_mae.append(mae(pred.stock_distributed, np.where(pred.preds < 0, 0, pred.preds)))\n",
    "            cv_rmse.append(rmse(pred.stock_distributed, np.where(pred.preds < 0, 0, pred.preds)))\n",
    "    \n",
    "    print('CV details is {}'.format([round(val, 4) for val in cv]))\n",
    "    print('CV-1 is {:.4f}, CV mean is {:.4f} and CV std is {:.4f}'.format(cv[0], np.array(cv).mean(), np.array(cv).std()))\n",
    "    \n",
    "    print('MASE-CV details is {}'.format([round(val, 4) for val in cv_mae]))\n",
    "    print('MASE-CV-1 is {:.4f}, mean is {:.4f} and std is {:.4f}'.format(cv_mae[0], np.array(cv_mae).mean(), np.array(cv_mae).std()))\n",
    "    \n",
    "    \n",
    "    if use_separate_model:\n",
    "        m = 'individual'\n",
    "    else:\n",
    "        m = 'base'\n",
    "    version = str(version)\n",
    "    \n",
    "    pred_overall.to_csv(f'data/temp/lgb_v{version}_{m}_pred.csv', index=False)\n",
    "    return pred_overall\n",
    "\n",
    "\n",
    "# Features Engineering\n",
    "def _read_data(features = [TARGET], path='data/'):\n",
    "    df = _combine_data(path=path)\n",
    "    df[features] = df[features].fillna(0)\n",
    "    print('Read data, data frame size: {}'.format(df.shape))\n",
    "    return df\n",
    "\n",
    "def _combine_data(path='data/'):\n",
    "    # Read raw data\n",
    "    train = pd.read_csv(path+'contraceptive_logistics_data.csv')\n",
    "    location = pd.read_csv(path+'service_delivery_site_data.csv')\n",
    "    product = pd.read_csv(path+'product.csv')\n",
    "\n",
    "    # Expand data frame\n",
    "    month_year = train[['year','month']].drop_duplicates().reset_index(drop=True)\n",
    "    product_site = train[['region','district','site_code','product_code']].drop_duplicates().reset_index(drop=True)\n",
    "    train_base = pd.merge(month_year.assign(j=1), product_site.assign(j=1)).drop(columns = 'j')\n",
    "    train = pd.merge(train_base, train, how='left')\n",
    "\n",
    "    # Add date and index\n",
    "    train['day'] = 1\n",
    "    train['ds'] = pd.to_datetime(train[['year','month','day']])\n",
    "    train = train.sort_values(by=['site_code','product_code','ds']).reset_index(drop=True)\n",
    "    train['isna'] = train['stock_distributed'].isna()\n",
    "    train['idx'] = train.groupby(['site_code','product_code'])['ds'].rank(method='first', ascending=True)\n",
    "    train = train.drop(columns = ['year','month','day'])\n",
    "\n",
    "    # Join with location\n",
    "    train = pd.merge(train, location.drop(columns=['site_region','site_district']))\n",
    "\n",
    "    # Join with product\n",
    "    train = pd.merge(train, product)\n",
    "\n",
    "    # Rearrange columns\n",
    "    train = train[['site_code','product_code'] + train.drop(columns=['site_code','product_code']).columns.tolist()]\n",
    "\n",
    "    # Change category\n",
    "    train = train.sort_values(by=['site_code','product_code','ds']).reset_index(drop=True)\n",
    "    train['idx'] = train['idx'].astype(int)\n",
    "    train['ds'] = train['ds'].dt.date.astype(str)\n",
    "    train['product_name'] = train['product_name'].str.strip()\n",
    "    \n",
    "    return(train)\n",
    "\n",
    "def _generate_test_set(df):\n",
    "    df_test = pd.DataFrame({})\n",
    "    for i, dt in enumerate(['2019-10-01','2019-11-01','2019-12-01']):\n",
    "        test_set = df[df['idx'] == 45].reset_index(drop=True)\n",
    "        test_set['idx'] = test_set['idx'] + i + 1\n",
    "        test_set['ds'] = dt\n",
    "        test_set[['stock_initial','stock_received','stock_distributed',\n",
    "                  'stock_adjustment','stock_end','average_monthly_consumption',\n",
    "                  'stock_stockout_days','stock_ordered']] = np.inf\n",
    "        df_test = df_test.append(test_set)\n",
    "    df = df.append(df_test).sort_values(by = ['site_code','product_code','idx']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def _get_cumulative_nonzero(df):\n",
    "    '''\n",
    "    This function needs to be used before any data removal \n",
    "    because of lagging or rolling features.\n",
    "    Exclude first NA or zero data by df.loc[df['isna_int'] > 0] or df.loc[df['iszero_int'] > 0].shape\n",
    "    '''\n",
    "    df['isna_int'] = [0 if x == True else 1 for x in df['isna']]\n",
    "    df['iszero_int'] = [0 if x == 0 else 1 for x in df['stock_distributed']]\n",
    "    df[['isna_int', 'iszero_int']] = df.groupby(['site_code', 'product_code'])[['isna_int', 'iszero_int']].transform(lambda x: x.cumsum())\n",
    "    print('Get cumulative nonzero flag')\n",
    "    return df\n",
    "\n",
    "def _get_mase_constant(df, test_block = 46, remove_first_na = True, remove_first_zero = False):\n",
    "    '''\n",
    "    This function needs to be used by applying `get_cumulative_nonzero` \n",
    "    to exclude first NA or zero data.\n",
    "    It also needs to be used before any data removal\n",
    "    The default test_block is 46 ( data) which will be used as the  (43 for latest CV)\n",
    "    constant of the mase denominator for each series.\n",
    "    In default, remove first NA data from the training set\n",
    "    '''\n",
    "    df['diff_abs'] = df.loc[(df['isna_int'] > 0) & (df['idx'] < test_block)].groupby(['site_code', 'product_code'])['stock_distributed'].transform(lambda x: abs(x-x.shift(1)))\n",
    "    df['mase_constant'] = df.groupby(['site_code', 'product_code'])['diff_abs'].transform(lambda x: x.mean())\n",
    "    df['mase_constant'] = 1 / df['mase_constant']\n",
    "    df['mase_constant'] = df['mase_constant'].replace(np.inf, 0).replace(np.nan, 0)\n",
    "    print('Get MASE constant')\n",
    "    return df\n",
    "\n",
    "def generate_lag_features(df, lag = [3,4], features = [TARGET]):\n",
    "    df = df.assign(**{\n",
    "            '{}_lag_{}'.format(col, l): df.groupby(['site_code', 'product_code'])[col].transform(lambda x: x.shift(l))\n",
    "            for l in lag\n",
    "            for col in features\n",
    "         })\n",
    "    lag_features = [col for col in df.columns if 'lag' in col]\n",
    "    df = df.dropna(subset = lag_features)\n",
    "    print('Generate lag features {}, data frame size: {}'.format(lag, df.shape))\n",
    "    return df \n",
    "\n",
    "def generate_diff_features(df, minus = True, ratio = False):\n",
    "    lag_features = [col for col in df.columns if 'lag' in col]\n",
    "    for i,j in combinations(lag_features, 2):\n",
    "        if minus:\n",
    "            df['{}_minus_{}'.format(i, j)] = df[i] - df[j]\n",
    "        if ratio:\n",
    "            df['{}_div_{}'.format(i, j)] = (df[i] / df[j]).fillna(0)\n",
    "    print('Generate diff features')\n",
    "    return df\n",
    "\n",
    "def generate_id(df):\n",
    "    df['id'] = df['site_code'] + '-' + df['product_code']\n",
    "    df['id'] = df['id'].astype('category')\n",
    "    print('Generate ID features')\n",
    "    return df\n",
    "\n",
    "def generate_date_features(df, use_month = True, use_quarter = False, use_year = False, use_category = True):\n",
    "    '''\n",
    "    Generate date features as category or integer, consists of:\n",
    "    month, quarter and year\n",
    "    '''\n",
    "    if use_month:\n",
    "        df['month'] = pd.to_datetime(df['ds']).dt.month\n",
    "    if use_quarter:\n",
    "        df['quarter'] = pd.to_datetime(df['ds']).dt.quarter\n",
    "    if use_year:\n",
    "        df['year'] = pd.to_datetime(df['ds']).dt.year\n",
    "    date_features = df.filter(regex = '^(month|quarter|year)$').columns.tolist()\n",
    "    if use_category:\n",
    "        df[date_features] = df[date_features].astype('category')\n",
    "    print('Generate date features {}'.format(date_features))\n",
    "    return df\n",
    "\n",
    "def get_weekend_in_month(df, use_percentage = False):\n",
    "    df['weekend_in_month'] = pd.to_datetime(df['ds']).dt.days_in_month - np.busday_count(\n",
    "        pd.to_datetime(df['ds']).dt.date.values.astype('datetime64[D]'), \n",
    "        (pd.to_datetime(df['ds']).dt.date + pd.DateOffset(months=1)).values.astype('datetime64[D]') \n",
    "    )\n",
    "    if use_percentage:\n",
    "        df['weekend_in_month'] = df['weekend_in_month'] / pd.to_datetime(df['ds']).dt.days_in_month\n",
    "    print('Get number of weekend days in month')\n",
    "    return df\n",
    "\n",
    "def get_day_in_month(df):\n",
    "    df['day_in_month'] = pd.to_datetime(df['ds']).dt.daysinmonth\n",
    "    print('Get days in month')\n",
    "    return df\n",
    "\n",
    "def remove_unnecessary_columns(df, column_list = []):\n",
    "    '''\n",
    "    Remove columns generated from features engineering process outside of \n",
    "    list from `remove_features`\n",
    "    '''\n",
    "    column_list_all = ['diff_abs'] + column_list\n",
    "    column_list_selected = list(set(column_list_all) & set(df.columns.tolist()))\n",
    "    df = df.drop(column_list_selected, axis = 1)\n",
    "    print('Remove unnecessary columns')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Error function\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))\n",
    "\n",
    "def mae(y, y_pred):\n",
    "    return np.mean(np.abs(y - y_pred))\n",
    "\n",
    "def mase_df(pred_df, clip_lower = True):\n",
    "    pred_df = pd.merge(pred_df, summary_block[['site_code', 'product_code', 'idx', 'mase_constant']])\n",
    "    if clip_lower:\n",
    "        pred_df[['preds']] = pred_df[['preds']].clip(lower = 0)\n",
    "    pred_df['scaled_error'] = abs(pred_df['stock_distributed'] - pred_df['preds']) * pred_df['mase_constant']\n",
    "    mase = pred_df.groupby(['site_code', 'product_code'])['scaled_error'].agg(lambda x: x.mean()).mean()\n",
    "    return mase\n",
    "\n",
    "def mae_row(pred_df, clip_lower = True):\n",
    "    if clip_lower:\n",
    "        pred_df[['preds']] = pred_df[['preds']].clip(lower = 0)\n",
    "    return(mae(pred_df.preds, pred_df.stock_distributed))\n",
    "\n",
    "\n",
    "# Modeling\n",
    "def process_train(df, test_block = 43, verbose = 500, is_print = True,\n",
    "                  use_log = False, use_weight = False,\n",
    "                  remove_first_na = False, remove_first_zero = False,\n",
    "                  version = 0):\n",
    "    \n",
    "    df = df.copy()\n",
    "    local_params = lgb_params.copy()           \n",
    "        \n",
    "    if use_log:\n",
    "        df[TARGET] = np.log1p(df[TARGET])\n",
    "\n",
    "    # Categorical feature\n",
    "    for col in categorical_features:\n",
    "        try:\n",
    "            df[col] = df[col].astype('category')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Our features\n",
    "    remove_additional_features = ['isna_int', 'iszero_int', 'mase_constant', 'diff_abs']\n",
    "    remove_additional_features_selected = list(set(remove_additional_features) & set(df.columns.tolist()))\n",
    "    all_features = [col for col in list(df) if col not in (remove_features + remove_additional_features_selected)]\n",
    "    if is_print: print(all_features)\n",
    "        \n",
    "    # Check lag\n",
    "    if len([col for col in all_features if 'lag_1' in col]) > 0:\n",
    "        block_next = 1\n",
    "    elif len([col for col in all_features if 'lag_2' in col]) > 0:\n",
    "        block_next = 2\n",
    "    else:\n",
    "        block_next = 3\n",
    " \n",
    "    if remove_first_na:\n",
    "        train_mask = (df['idx']<test_block) & (df['isna_int']>0)\n",
    "    elif remove_first_zero:\n",
    "        train_mask = (df['idx']<test_block) & (df['iszero_int']>0)\n",
    "    else:\n",
    "        train_mask = df['idx']<test_block\n",
    "    valid_mask = (df['idx'].isin(range(test_block,test_block + block_next))) & (df['isna'] == False)\n",
    "    \n",
    "    if use_weight:\n",
    "        train_data = lgb.Dataset(df[train_mask][all_features], label=df[train_mask][TARGET], weight=df[train_mask]['mase_constant'])\n",
    "        valid_data = lgb.Dataset(df[valid_mask][all_features], label=df[valid_mask][TARGET], weight=df[valid_mask]['mase_constant'])\n",
    "    else:\n",
    "        train_data = lgb.Dataset(df[train_mask][all_features], label=df[train_mask][TARGET])\n",
    "        valid_data = lgb.Dataset(df[valid_mask][all_features], label=df[valid_mask][TARGET])\n",
    "    \n",
    "    print('Train data frame size: ({}, {})'.format(len(train_mask[train_mask]), len(all_features)))\n",
    "    print('Train time block', df[train_mask]['idx'].min(), df[train_mask]['idx'].max())\n",
    "    if is_print: \n",
    "        print('Valid time block', df[valid_mask]['idx'].min(), df[valid_mask]['idx'].max())\n",
    "\n",
    "    temp_df = df[valid_mask]\n",
    "    del df\n",
    "    seed_everything(SEED)\n",
    "    if test_block != 46:\n",
    "        estimator = lgb.train(local_params,\n",
    "                              train_data,\n",
    "                              valid_sets = [valid_data],\n",
    "                              verbose_eval = verbose) \n",
    "    else:\n",
    "        if 'early_stopping_rounds' in local_params: \n",
    "            del local_params['early_stopping_rounds']\n",
    "        estimator = lgb.train(local_params,\n",
    "                              train_data) \n",
    "        \n",
    "    temp_df['preds'] = estimator.predict(temp_df[all_features])\n",
    "    if use_log:\n",
    "        temp_df['preds'] = np.expm1(temp_df['preds'])\n",
    "        temp_df[TARGET] = np.expm1(temp_df[TARGET])\n",
    "    temp_df = temp_df[['site_code','product_code','idx',TARGET,'preds']]\n",
    "    if ('mase_constant' in remove_additional_features_selected) & (test_block != 46):\n",
    "        print('MASE is {}'.format(mase_df(temp_df)))\n",
    "    return estimator, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mase_df_all(df, df_name):\n",
    "    print(df_name)\n",
    "    cv = []\n",
    "    for block in [43,40,37,34]:\n",
    "        cv_block = mase_df(df[df['block'] == block])\n",
    "        cv.append(cv_block)\n",
    "        print('{} is {}'.format(block, cv_block))\n",
    "    print('CV mean is {:.4f} and CV std is {:.4f}'.format(np.array(cv).mean(), np.array(cv).std()))\n",
    "    print('')\n",
    "    \n",
    "def generate_submission(sub, name):\n",
    "    # Main submission\n",
    "    sub = sub[sub['block'] == 46].copy()\n",
    "    sub['year'] = 2019\n",
    "    sub.loc[sub['idx'] == 46, 'month'] = 10\n",
    "    sub.loc[sub['idx'] == 47, 'month'] = 11\n",
    "    sub.loc[sub['idx'] == 48, 'month'] = 12\n",
    "    sub = sub.loc[:, ['year','month','site_code','product_code','preds']]\n",
    "    sub[['preds']] = sub[['preds']].clip(lower = 0)\n",
    "    \n",
    "    # If not found, use median value\n",
    "    sub_median = _read_data()\n",
    "    sub_median = sub_median[sub_median['isna'] == False]\n",
    "    sub_median = sub_median.groupby(['site_code','product_code']). \\\n",
    "                            agg({'stock_distributed': 'median'}).reset_index()\n",
    "    \n",
    "    # Join with sub_format.csv\n",
    "    sub_format = pd.read_csv('data/submission_format.csv')\n",
    "    sub_final = pd.merge(sub_format, sub, how='left')\n",
    "    sub_final = pd.merge(sub_final, sub_median, how='left')\n",
    "    \n",
    "    # Coalesce: main submission -> median -> 0\n",
    "    sub_final['predicted_value'] = sub_final[['preds','stock_distributed','predicted_value']]. \\\n",
    "                                   bfill(axis=1).iloc[:,0]\n",
    "    sub_final = sub_final.drop(columns = ['preds','stock_distributed'])\n",
    "    print('Generate submission')\n",
    "    sub_final.to_csv(name, index=False)\n",
    "    print('Total prediction average per month ', sub_final.predicted_value.sum()/3)\n",
    "    return sub_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get MASE constant (denominator) for each CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data, data frame size: (61065, 20)\n",
      "Get cumulative nonzero flag\n",
      "Get MASE constant\n",
      "Get MASE constant\n",
      "Get MASE constant\n",
      "Get MASE constant\n",
      "Get MASE constant\n"
     ]
    }
   ],
   "source": [
    "summary_block = get_mase_constant_agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model1 prediction\n",
    "ensemble = pd.read_csv('data/ensemble1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find threshold value to clip predictions to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Ensemble\n",
      "43 is 0.9456125865871512\n",
      "40 is 1.1228356729569315\n",
      "37 is 1.0123106243720073\n",
      "34 is 1.0260220894225602\n",
      "CV mean is 1.0267 and CV std is 0.0633\n",
      "\n",
      "0.75\n",
      "Ensemble\n",
      "43 is 0.9348655547255108\n",
      "40 is 1.1190229454392604\n",
      "37 is 1.0067022566572967\n",
      "34 is 1.0164373090435619\n",
      "CV mean is 1.0193 and CV std is 0.0657\n",
      "\n",
      "0.5\n",
      "Ensemble\n",
      "43 is 0.9380610079812338\n",
      "40 is 1.1184961189942244\n",
      "37 is 1.0076293077409175\n",
      "34 is 1.0184234624630242\n",
      "CV mean is 1.0207 and CV std is 0.0644\n",
      "\n",
      "0.25\n",
      "Ensemble\n",
      "43 is 0.9424471034760905\n",
      "40 is 1.120122129460088\n",
      "37 is 1.009977461666945\n",
      "34 is 1.0210834478434152\n",
      "CV mean is 1.0234 and CV std is 0.0634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0,0.75,0.5,0.25]:\n",
    "    print(threshold)\n",
    "    mase_df_all(ensemble.assign(preds = 1*np.where(ensemble['preds'] < threshold, 0, ensemble['preds'])), 'Ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find multiplication factor with lower mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Ensemble\n",
      "43 is 0.9348655547255108\n",
      "40 is 1.1190229454392604\n",
      "37 is 1.0067022566572967\n",
      "34 is 1.0164373090435619\n",
      "CV mean is 1.0193 and CV std is 0.0657\n",
      "\n",
      "1.05\n",
      "Ensemble\n",
      "43 is 0.9343343771652075\n",
      "40 is 1.1167642509396747\n",
      "37 is 1.0030622037581958\n",
      "34 is 1.016032040905569\n",
      "CV mean is 1.0175 and CV std is 0.0652\n",
      "\n",
      "1.04\n",
      "Ensemble\n",
      "43 is 0.9342490676749443\n",
      "40 is 1.1170500664168415\n",
      "37 is 1.0035990820321674\n",
      "34 is 1.015983189872644\n",
      "CV mean is 1.0177 and CV std is 0.0653\n",
      "\n",
      "1.03\n",
      "Ensemble\n",
      "43 is 0.9342890434822978\n",
      "40 is 1.1174114113061555\n",
      "37 is 1.0042252300205041\n",
      "34 is 1.0160031556781168\n",
      "CV mean is 1.0180 and CV std is 0.0654\n",
      "\n",
      "1.02\n",
      "Ensemble\n",
      "43 is 0.934422074822458\n",
      "40 is 1.1178652150901416\n",
      "37 is 1.0049477952992028\n",
      "34 is 1.01606904453117\n",
      "CV mean is 1.0183 and CV std is 0.0654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for factor in [1,1.05,1.04,1.03,1.02]:\n",
    "    print(factor)\n",
    "    mase_df_all(ensemble.assign(preds = factor*np.where(ensemble['preds'] < 0.75, 0, ensemble['preds'])), 'Ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find multiplication factor with lower mean and standard deviation with different factor for each horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "Ensemble\n",
      "43 is 0.9348655547255108\n",
      "40 is 1.1190229454392604\n",
      "37 is 1.0067022566572967\n",
      "34 is 1.0164373090435619\n",
      "CV mean is 1.0193 and CV std is 0.0657\n",
      "\n",
      "[1.05, 1.05, 1.05]\n",
      "Ensemble\n",
      "43 is 0.9343343771652075\n",
      "40 is 1.1167642509396747\n",
      "37 is 1.0030622037581958\n",
      "34 is 1.016032040905569\n",
      "CV mean is 1.0175 and CV std is 0.0652\n",
      "\n",
      "[1.0, 1.05, 1.1]\n",
      "Ensemble\n",
      "43 is 0.9358246284441805\n",
      "40 is 1.1161212758075052\n",
      "37 is 1.0021717302607926\n",
      "34 is 1.019233091313018\n",
      "CV mean is 1.0183 and CV std is 0.0645\n",
      "\n",
      "[1.05, 1.05, 1.1]\n",
      "Ensemble\n",
      "43 is 0.9349854301531038\n",
      "40 is 1.1161320556860792\n",
      "37 is 1.0008551185685406\n",
      "34 is 1.0167135704247088\n",
      "CV mean is 1.0172 and CV std is 0.0648\n",
      "\n",
      "[1.05, 1.1, 1.15]\n",
      "Ensemble\n",
      "43 is 0.9377752920070049\n",
      "40 is 1.116158611653319\n",
      "37 is 1.0000711406522447\n",
      "34 is 1.0203339135569174\n",
      "CV mean is 1.0186 and CV std is 0.0640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Different factor for each horizon\n",
    "for factor in [[1,1,1],[1.05,1.05,1.05],[1.0,1.05,1.1],[1.05,1.05,1.1],[1.05,1.1,1.15]]:\n",
    "    print(factor)\n",
    "    \n",
    "    horizon1 = ensemble[(ensemble['idx'] - ensemble['block']) == 0]\n",
    "    horizon2 = ensemble[(ensemble['idx'] - ensemble['block']) == 1]\n",
    "    horizon3 = ensemble[(ensemble['idx'] - ensemble['block']) == 2]\n",
    "    horizon1 = horizon1.assign(preds = factor[0]*np.where(horizon1['preds'] < 0.75, 0, horizon1['preds']))\n",
    "    horizon2 = horizon2.assign(preds = factor[1]*np.where(horizon2['preds'] < 0.75, 0, horizon2['preds']))\n",
    "    horizon3 = horizon3.assign(preds = factor[2]*np.where(horizon3['preds'] < 0.75, 0, horizon3['preds']))\n",
    "    \n",
    "    mase_df_all(pd.concat([horizon1,horizon2,horizon3]), 'Ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon1 = ensemble[(ensemble['idx'] - ensemble['block']) == 0]\n",
    "horizon2 = ensemble[(ensemble['idx'] - ensemble['block']) == 1]\n",
    "horizon3 = ensemble[(ensemble['idx'] - ensemble['block']) == 2]\n",
    "horizon1 = horizon1.assign(preds = factor[0]*np.where(horizon1['preds'] < 0.75, 0, horizon1['preds']))\n",
    "horizon2 = horizon2.assign(preds = factor[1]*np.where(horizon2['preds'] < 0.75, 0, horizon2['preds']))\n",
    "horizon3 = horizon3.assign(preds = factor[2]*np.where(horizon3['preds'] < 0.75, 0, horizon3['preds']))\n",
    "ensemble_postprocess = pd.concat([horizon1,horizon2,horizon3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble-Postprocess\n",
      "43 is 0.9377752920070049\n",
      "40 is 1.116158611653319\n",
      "37 is 1.0000711406522447\n",
      "34 is 1.0203339135569174\n",
      "CV mean is 1.0186 and CV std is 0.0640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mase_df_all(ensemble_postprocess, 'Ensemble-Postprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data, data frame size: (61065, 20)\n",
      "Generate submission\n",
      "Total prediction average per month  13919.171485192672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>site_code</th>\n",
       "      <th>product_code</th>\n",
       "      <th>predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27134</td>\n",
       "      <td>8.576486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27137</td>\n",
       "      <td>1.648830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>C4001</td>\n",
       "      <td>AS27138</td>\n",
       "      <td>3.998565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27139</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27137</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>C5076</td>\n",
       "      <td>AS27133</td>\n",
       "      <td>2.634868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3115 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month site_code product_code  predicted_value\n",
       "0     2019     10     C4001      AS27134         8.576486\n",
       "1     2019     10     C4001      AS27132         0.000000\n",
       "2     2019     10     C4001      AS27000         0.000000\n",
       "3     2019     10     C4001      AS27137         1.648830\n",
       "4     2019     10     C4001      AS27138         3.998565\n",
       "...    ...    ...       ...          ...              ...\n",
       "3110  2019     12     C5076      AS27000         0.000000\n",
       "3111  2019     12     C5076      AS27139         0.000000\n",
       "3112  2019     12     C5076      AS27137         0.000000\n",
       "3113  2019     12     C5076      AS27138         0.000000\n",
       "3114  2019     12     C5076      AS27133         2.634868\n",
       "\n",
       "[3115 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_submission(ensemble_postprocess, 'submission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction output for model2\n",
    "ensemble_postprocess.to_csv('data/ensemble_postprocess.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
