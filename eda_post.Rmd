---
title: "USAID's Intelligent Forecasting: Post EDA"
author: "Rasyid Ridha"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
    code_folding: hide
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE, 
  message = FALSE,
  fig.path = "figs/"
)
```

The goals are to evaluate forecast result and do post-processing which can improve the scores

* Evaluate all models: LGB, ARIMA, regression
* Evaluate MAE score
* Evaluate MASE score
* Evaluate forecast result (high error vs low error)
* Best model selection (how can we push the model?)

```{r library}
library(lubridate)
library(tidyverse)
library(hrbrthemes)
library(forcats)
library(plotly)
library(feather)
library(skimr)
library(mrsq)
library(GGally)
theme_set(theme_nunito())
```

```{r read-data}
# Read train
train <- read_feather("data/clean/ifc_clean.feather")
train <- train %>%
  mutate(stock_distributed = replace_na(stock_distributed, 0))

# Read MASE denom
summary_diff <- read_feather("data/clean/denom_v1.feather")
summary_diff_spread <- summary_diff %>% 
  select(-cnt, -is_eligible) %>% 
  gather(block, mase_constant, -site_code, -product_code) %>% 
  mutate(block = gsub("val_diff_|val_diff_cv_", "", block),
         block = ifelse(block == "test", "46", block),
         block = as.integer(block),
         mase_constant = ifelse(is.na(mase_constant), 0, mase_constant))

# Aggregate for each site and product
summary_train <- train %>% 
  group_by(site_code, product_code) %>% 
  summarise(stock_distributed_sum = sum(stock_distributed))
```

```{r quick-snippet}
# Read prediction csv
read_prediction <- function(path, method_name = NULL) {
  x <- read.csv(path) %>% 
    mutate(preds = ifelse(preds < 0, 0, preds),
           ae = abs(stock_distributed - preds))
  if (length(method_name) > 0) {
    x <- x %>% 
      mutate(method = method_name) %>% 
      select(method, everything())
  }
  x
}

# Visualize aggregated series
visualize_agg_prediction <- function(res_df) {
  p <- train %>% 
    group_by(ds) %>% 
    summarise(stock_distributed = sum(stock_distributed)) %>% 
    ungroup() %>% 
    mutate(cat = "Actual") %>% 
    bind_rows(res_df %>% 
                group_by(block, idx) %>% 
                summarise(preds = sum(preds)) %>% 
                ungroup() %>% 
                transmute(ds = as.Date("2018-10-01") + months(idx - 34),
                          stock_distributed = preds,
                          cat = paste0("CV-", block))) %>% 
    ggplot(aes(ds, stock_distributed, color = cat)) +
    geom_line() +
    labs(title = paste0(unique(res_df$method), collapse = ","))
  ggplotly(p) 
}

# Visualize specific series
visualize_specific_prediction <- function(res_df,
                                          site = "C1024", 
                                          product = "AS27000",
                                          rank = 0) {
  p <- train %>% 
    select(ds, site_code, product_code, stock_distributed) %>% 
    mutate(cat = "Actual") %>% 
    bind_rows(res_df %>% 
                transmute(ds = as.Date("2018-10-01") + months(idx - 34),
                          site_code, product_code,
                          stock_distributed = preds,
                          error = ae,
                          cat = paste0("CV-", block))) %>% 
    filter(product_code == product,
           site_code == site) %>% 
    ggplot(aes(ds, stock_distributed, color = cat)) +
    geom_line() +
    labs(title = paste(rank, site, product, sep = "-"))
  p
}

visualize_specific_prediction_top_bottom <- function(res_df, type = "top", n = 3) {
  res_summary <- res_df %>% 
    group_by(site_code, product_code) %>% 
    summarise(mae = mean(ae),
              actual = sum(stock_distributed)) %>% 
    ungroup() %>% 
    arrange(desc(mae)) %>% 
    mutate(r = row_number())
  if (type == "top") {
    res_summary <- res_summary %>% 
      arrange(desc(mae), desc(actual)) %>% 
      head(n)
  } else {
    res_summary <- res_summary %>% 
      filter(actual > 0) %>% 
      mutate(mae_ratio = mae / actual) %>% 
      arrange(mae_ratio) %>% 
      head(n)
  }
  output <- list()
  for (i in 1:nrow(res_summary)) {
    print(i)
    visualize_specific_prediction(res_df, 
                                  site = res_summary$site_code[i],
                                  product = res_summary$product_code[i],
                                  rank = res_summary$r[i]) -> output[[i]]
  }
  output
}
```

```{r read-pred-result}
# Baseline LGB
res_lgb <- read_prediction("data/temp/lgb_baseline_pred.csv", "LGB")

# Baseline LGB with separate individual models
res_lgb_iv <- read_prediction("data/temp/lgb_individual_pred.csv", "LGB-i")

# Baseline LGB using all features, optimizing RMSE
res_lgb_all_rmse <- read_prediction("data/temp/lgb_individual_allf_pred_rmse.csv", "LGB-iar")

# Baseline LGB using all features, separate individual models
res_lgb_all <- read_prediction("data/temp/lgb_individual_allf_pred.csv", "LGB-ia")

# R model
res <- read_prediction("data/temp/res_all.csv")
```

```{r get-summary-all}
# Combine and get summary for each series
summary_res <- bind_rows(
  res_lgb,
  res_lgb_all,
  res_lgb_all_rmse,
  res_lgb_iv,
  res
  ) %>% 
  group_by(method, site_code, product_code, block) %>% 
  summarise(mae = mean(ae)) %>% 
  ungroup() %>% 
  left_join(summary_diff_spread) %>% 
  left_join(summary_diff_spread %>% 
              filter(block == 46) %>% 
              select(-block) %>% 
              rename(mase_constant_fix = mase_constant)) %>% 
  mutate(mase = mae / mase_constant,
         mase = ifelse(mase_constant == 0, 0, mase),
         mase_2 = mae / mase_constant_fix,
         mase_2 = ifelse(mase_constant_fix == 0, 0, mase_2))
write_rds(summary_res, "data/clean/summary_res.rds")
```

## Evaluation

### Can you predict Zero? 

Using baseline LGB, most of zero time series predict no zero value but it is okay since the value is very low

```{r is-zero}
res_lgb %>% 
  inner_join(summary_train %>%
               filter(stock_distributed_sum == 0)) %>%
  mutate(is_zero = ae == 0) %>% 
  group_by(is_zero) %>% 
  summarise(n = n(),
            pred_avg = mean(preds))
```

### Overall prediction {.tabset}

Evaluate on overall prediction from models that we have

#### LGB

Since we use MAE as the objective, the overall forecast is very low

```{r overall-pred-lgb}
visualize_agg_prediction(res_lgb)
```

#### LGB-i

```{r overall-pred-lgb-i}
visualize_agg_prediction(res_lgb_iv)
```

#### LGB-ia

```{r overall-pred-lgb-ia}
visualize_agg_prediction(res_lgb_all)
```

#### LGB-iar

Optimize RMSE, quite match with aggregated result

```{r overall-pred-lgb-iar}
visualize_agg_prediction(res_lgb_all_rmse)
```

#### ARIMA

```{r overall-arima}
res %>% 
  filter(method == "ARIMA") %>% 
  visualize_agg_prediction()
```

#### ETS

```{r overall-ets}
res %>% 
  filter(method == "ETS") %>% 
  visualize_agg_prediction()
```

#### Naive

```{r overall-naive}
res %>% 
  filter(method == "Naive") %>% 
  visualize_agg_prediction()
```

#### Regression

```{r overall-regression}
res %>% 
  filter(method == "Regression") %>% 
  visualize_agg_prediction()
```

#### XGBoost

```{r overall-xgboost}
res %>% 
  filter(method == "XGBoost") %>% 
  visualize_agg_prediction()
```

### Individual prediction {.tabset}

Evaluate on individual prediction from models that we have, take highest and lowest error

#### LGB

```{r individual-pred-lgb}
visualize_specific_prediction_top_bottom(res_lgb)
visualize_specific_prediction_top_bottom(res_lgb, "bottom")
```

#### LGB-i

```{r individual-pred-lgb-i}
visualize_specific_prediction_top_bottom(res_lgb_iv)
visualize_specific_prediction_top_bottom(res_lgb_iv, "bottom")
```

#### LGB-ia

```{r individual-pred-lgb-ia}
visualize_specific_prediction_top_bottom(res_lgb_all)
visualize_specific_prediction_top_bottom(res_lgb_all, "bottom")
```

#### LGB-iar

```{r individual-pred-lgb-iar}
visualize_specific_prediction_top_bottom(res_lgb_all_rmse)
visualize_specific_prediction_top_bottom(res_lgb_all_rmse, "bottom")
```

#### ARIMA

```{r individual-pred-arima}
visualize_specific_prediction_top_bottom(filter(res, method == "ARIMA"))
visualize_specific_prediction_top_bottom(filter(res, method == "ARIMA"), "bottom")
```

#### ETS

```{r individual-pred-ets}
visualize_specific_prediction_top_bottom(filter(res, method == "ETS"))
visualize_specific_prediction_top_bottom(filter(res, method == "ETS"), "bottom")
```

#### Naive

```{r individual-pred-naive}
visualize_specific_prediction_top_bottom(filter(res, method == "Naive"))
visualize_specific_prediction_top_bottom(filter(res, method == "Naive"), "bottom")
```

#### Regression

```{r individual-pred-regression}
visualize_specific_prediction_top_bottom(filter(res, method == "Regression"))
visualize_specific_prediction_top_bottom(filter(res, method == "Regression"), "bottom")
```

#### XGBoost

```{r individual-pred-xgboost}
visualize_specific_prediction_top_bottom(filter(res, method == "XGBoost"))
visualize_specific_prediction_top_bottom(filter(res, method == "XGBoost"), "bottom")
```

## Ensemble

### MAE

```{r mae-cv-correl}
summary_res_spread <- summary_res %>% 
  select(method, mae, site_code, product_code, block) %>% 
  spread(method, mae) 
summary_res_spread %>% 
  select(-block) %>% 
  ggcorr(label = TRUE, label_round = 2)
```

```{r mae-overall}
summary_res_spread %>% 
  group_by(block) %>% 
  summarise_if(is.numeric, mean) %>% 
  ungroup() %>% 
  mutate(best_lgb_improvement = -(`LGB-ia` / Naive - 1))
```

### MASE

```{r mase-cv-correl}
summary_res_mase_spread <- summary_res %>% 
  select(method, mase, site_code, product_code, block) %>% 
  spread(method, mase) 
summary_res_mase_spread %>% 
  select(-block) %>% 
  ggcorr(label = TRUE, label_round = 2)
```

```{r mase-overall}
summary_res_mase_spread %>% 
  group_by(block) %>% 
  summarise_if(is.numeric, mean) %>% 
  ungroup() %>% 
  mutate(best_lgb_improvement = -(`LGB-ia` / Naive - 1))
```

```{r mase-2}
summary_res %>% 
  select(method, mase_2, site_code, product_code, block) %>% 
  spread(method, mase_2) %>% 
  group_by(block) %>% 
  summarise_if(is.numeric, mean) %>% 
  ungroup() %>% 
  mutate(best_lgb_improvement = -(`LGB-ia` / Naive - 1))
```

```{r mase-summary}
summary_res %>% 
  filter(block %in% c(43, 40, 37, 34)) %>% 
  group_by(block, method) %>% 
  summarise_at(vars(mae, mase), mean) %>% 
  ungroup() %>% 
  group_by(method) %>% 
  summarise(mase_avg = mean(mase),
            mase_sd = sd(mase),
            mae_avg = mean(mae),
            mae_sd = sd(mae)) %>% 
  arrange(mase_avg)
```

### MASE vs MAE Correlation

Series by series correlation is very small ~13%

```{r mase-mae-correl}
summary_res %>% 
  select(mae, mase) %>% 
  cor()
```

If we see by series, it's around ~47%

```{r mase-mae-summary-correl}
summary_res %>% 
  group_by(block, method) %>% 
  summarise_at(vars(mae, mase), mean) %>% 
  ungroup() %>% 
  select(mae, mase) %>% 
  cor()
```

```{r mase-mae-summary-correl-viz}
p <- summary_res %>% 
  # filter(block == 43) %>% 
  group_by(block, method) %>% 
  summarise_at(vars(mae, mase), mean) %>% 
  ungroup() %>% 
  ggplot(aes(mae, mase, color = method, size = block)) +
  geom_point(alpha = 0.7) +
  scale_size(range = c(1,4))
ggplotly(p)
```

### Best Model Selection

Let's combine the model! Using best model selection first!

```{r best-selection}
best_selection <- summary_res %>% 
  ungroup() %>% 
  arrange(site_code, product_code, mae) %>% 
  group_by(site_code, product_code, block) %>% 
  mutate(r = row_number()) %>% 
  filter(r == 1) %>% 
  select(-r) %>% 
  ungroup()
best_selection %>% 
  group_by(block) %>% 
  summarise(mase_avg = mean(mase),
            mae_avg = mean(mae)) %>% 
  ungroup()
```

It's superb! We can get MAE 6.xx using best selection method for all 10 models pool. Dramatic! Let's see which model are the best?

```{r best-selection-share}
# Remove MASE constant = 0 and MAE = 0
best_selection %>% 
  filter(mase_constant != 0, mae != 0) %>% 
  count(block, method) %>% 
  group_by(block) %>% 
  mutate(n_all = sum(n),
         p = n / sum(n)) %>% 
  select(-n) %>% 
  spread(method, p)
```

```{r best-selection-share-viz}
best_selection %>% 
  filter(mase_constant != 0, mae != 0) %>% 
  count(block, method) %>% 
  group_by(block) %>% 
  mutate(n_all = sum(n),
         p = n / sum(n)) %>% 
  select(-n) %>% 
  ggplot(aes(reorder(method, p), p)) +
  geom_boxplot() +
  coord_flip() +
  scale_y_continuous(limits = c(0, 0.25), labels = scales::percent) +
  labs(x = NULL)
```

Our best model leads but interestingly worse models like LGB-iar and Naive can give a huge contribution. Superb!

```{r best-selection-custom}
best_selection <- summary_res %>% 
  filter(method %in% c("LGB-ia", "Naive")) %>% 
  arrange(site_code, product_code, mase) %>% 
  group_by(site_code, product_code, block) %>% 
  mutate(r = row_number()) %>% 
  filter(r == 1) %>% 
  select(-r) %>% 
  ungroup()
best_selection %>% 
  group_by(block) %>% 
  summarise(mase_2_mean = mean(mase_2),
            mase_mean = mean(mase),
            mae_mean = mean(mae)) %>% 
  ungroup()
```
 
Quite good, we can reach 8.xx with help from Naive!
 
```{r best-selection-custom-share}
best_selection %>% 
  filter(mase_constant != 0, mae != 0) %>% 
  count(block, method) %>% 
  group_by(block) %>% 
  mutate(n_all = sum(n),
         p = n / sum(n)) %>% 
  select(-n) %>% 
  spread(method, p)
```

Since we use best model selection, what if we use averaging ensemble, or selecting the model based on specific criteria?

#### Best Selection Specific

Best selection method based on previous block

```{r avg-best-selection}
# Best selection based on average previous block before 43
avg_best_selection <- summary_res %>% 
  # Filter model that you want to ensemble
  # filter(method %in% c("LGB-ia", "ARIMA")) %>% 
  filter(block < 43) %>% 
  group_by(method, site_code, product_code) %>% 
  summarise(mae = mean(mae),
            mase = mean(mase)) %>% 
  ungroup() %>% 
  mutate(default_model = case_when(method == "LGB-ia" ~ 1,
                                   method == "Naive" ~ 4,
                                   method == "SNaive" ~ 5,
                                   method == "ETS" ~ 2,
                                   method == "ARIMA" ~ 3,
                                   TRUE ~ 6)) %>% 
  mutate(default_model = 0) %>%
  arrange(site_code, product_code, mase, mae, default_model) %>% 
  group_by(site_code, product_code) %>% 
  mutate(r = row_number()) %>% 
  filter(r == 1) %>% 
  select(-r) %>% 
  ungroup()

# Select best method
avg_best_selection <- summary_res %>% 
  filter(method == "LGB-ia") %>% 
  filter(block == 43) %>%
  anti_join(avg_best_selection %>% 
                   select(-mae, -mase, -method)) %>% 
  bind_rows(
    summary_res %>% 
      filter(block == 43) %>%
      inner_join(avg_best_selection %>% 
                   select(-mae, -mase))
  )
avg_best_selection %>% 
  count(method)
avg_best_selection %>% 
  group_by(block) %>% 
  summarise(mase_2_avg = mean(mase_2),
            mase_avg = mean(mase),
            mae_avg = mean(mae)) %>% 
  arrange(block)
```

MAE is getting better, it applies to MASE as well but the improvement is very small :)

### Averaging

```{r averaging-function}
average_ensemble <- function(df) {
  df %>%  
    group_by(site_code, product_code, idx, stock_distributed, block) %>% 
    summarise(preds = mean(preds)) %>% 
    ungroup() %>% 
    mutate(ae = abs(stock_distributed - preds)) %>% 
    group_by(site_code, product_code, block) %>% 
    summarise(mae = mean(ae)) %>% 
    ungroup() %>% 
    left_join(summary_diff_spread) %>% 
    left_join(summary_diff_spread %>% 
                filter(block == 46) %>% 
                select(-block) %>% 
                rename(mase_constant_fix = mase_constant)) %>% 
    mutate(mase = mae / mase_constant,
           mase = ifelse(mase_constant == 0, 0, mase),
           mase_2 = mae / mase_constant_fix,
           mase_2 = ifelse(mase_constant_fix == 0, 0, mase_2))
}
get_block_summary <- function(df) {
  df %>% 
    group_by(block) %>% 
    summarise(mae = mean(mae),
              mase = mean(mase)) %>% 
    ungroup()
}
get_all_summary <- function(df) {
  df %>% 
    filter(block %in% c(43, 40, 37, 34)) %>% 
    summarise(mase_avg = mean(mase),
              mase_sd = sd(mase),
              mae_avg = mean(mae),
              mae_sd = sd(mae)) %>% 
    arrange(mase_avg)
}
```

```{r averaging-pred-1}
ensemble_summary <- bind_rows(
  res_lgb,
  res_lgb_all,
  res_lgb_all_rmse,
  res_lgb_iv,
  res
  ) %>% 
  average_ensemble()
ensemble_summary %>% 
  get_block_summary() %>% 
  get_all_summary()
```

Not good enough

```{r averaging-pred-2}
ensemble_summary <- bind_rows(
  res_lgb,
  res_lgb_all,
  res_lgb_all_rmse,
  res_lgb_iv,
  ) %>% 
  average_ensemble()
ensemble_summary %>% 
  get_block_summary() %>% 
  get_all_summary()
```

```{r averaging-pred-3}
ensemble_summary <- bind_rows(
  res_lgb_all,
  res_lgb_all_rmse,
  filter(res, method == "Naive")
  ) %>% 
  average_ensemble()
ensemble_summary %>% 
  get_block_summary() %>% 
  get_all_summary()
```

Not good :(
