---
title: "USAID's Intelligent Forecasting: Post EDA"
author: "Rasyid Ridha"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
    code_folding: hide
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE, 
  message = FALSE,
  fig.path = "figs/"
)
```

The goals are to evaluate forecast result and do post-processing which can improve the scores

* Evaluate all models: LGB, ARIMA, regression
* Evaluate MAE score
* Evaluate MASE score
* Evaluate forecast result (high error vs low error)
* Best model selection (how can we push the model?)

```{r library}
library(lubridate)
library(tidyverse)
library(hrbrthemes)
library(forcats)
library(plotly)
library(feather)
library(skimr)
library(mrsq)
library(GGally)
theme_set(theme_nunito())
```

```{r read-data}
# Read train
train <- read_feather("data/clean/ifc_clean.feather")
train <- train %>%
  mutate(stock_distributed = replace_na(stock_distributed, 0))

# Read MASE denom
summary_diff <- read_feather("data/clean/denom_v1.feather")

# Aggregate for each site and product
summary_train <- train %>% 
  group_by(site_code, product_code) %>% 
  summarise(stock_distributed_sum = sum(stock_distributed))
```

```{r quick-snippet}
# Read prediction csv
read_prediction <- function(path, method_name = NULL) {
  x <- read.csv(path) %>% 
    mutate(preds = ifelse(preds < 0, 0, preds),
           ae = abs(stock_distributed - preds))
  if (length(method_name) > 0) {
    x <- x %>% 
      mutate(method = method_name) %>% 
      select(method, everything())
  }
  x
}

# Visualize aggregated series
visualize_agg_prediction <- function(res_df) {
  p <- train %>% 
    group_by(ds) %>% 
    summarise(stock_distributed = sum(stock_distributed)) %>% 
    ungroup() %>% 
    mutate(cat = "Actual") %>% 
    bind_rows(res_df %>% 
                group_by(block, idx) %>% 
                summarise(preds = sum(preds)) %>% 
                ungroup() %>% 
                transmute(ds = as.Date("2018-10-01") + months(idx - 34),
                          stock_distributed = preds,
                          cat = paste0("CV-", block))) %>% 
    ggplot(aes(ds, stock_distributed, color = cat)) +
    geom_line()
  ggplotly(p) 
}

# Visualize specific series
visualize_specific_prediction <- function(res_df,
                                          site = "C1024", 
                                          product = "AS27000") {
  p <- train %>% 
    select(ds, site_code, product_code, stock_distributed) %>% 
    mutate(cat = "Actual") %>% 
    bind_rows(res_df %>% 
                transmute(ds = as.Date("2018-10-01") + months(idx - 34),
                          site_code, product_code,
                          stock_distributed = preds,
                          error = ae,
                          cat = paste0("CV-", block))) %>% 
    filter(product_code == product,
           site_code == site) %>% 
    ggplot(aes(ds, stock_distributed, color = cat)) +
    geom_line() 
  ggplotly(p)
  }
```

```{r read-pred-result}
# Baseline LGB
res_lgb <- read_prediction("data/temp/lgb_baseline_pred.csv", "LGB")

# Baseline LGB with separate individual models
res_lgb_iv <- read_prediction("data/temp/lgb_individual_pred.csv", "LGB-i")

# Baseline LGB using all features, optimizing RMSE
res_lgb_all_rmse <- read_prediction("data/temp/lgb_individual_allf_pred_rmse.csv", "LGB-iar")

# Baseline LGB using all features, separate individual models
res_lgb_all <- read_prediction("data/temp/lgb_individual_allf_pred.csv", "LGB-ia")

# R model
res <- read_prediction("data/temp/res_all.csv")
```

## LGB Evaluation

We would like to evaluate our LGB model

### Can you predict Zero? 

Most of zero time series predict no zero value but it is okay since the value is very low

```{r is-zero}
res_lgb %>% 
  inner_join(summary_train %>%
               filter(stock_distributed_sum == 0)) %>%
  mutate(is_zero = ae == 0) %>% 
  group_by(is_zero) %>% 
  summarise(n = n(),
            pred_avg = mean(preds))
```

### Overall prediction

Let's use baseline LGB for this. It seems that the overall prediction is very low!

```{r overall-pred}
visualize_agg_prediction(res_lgb)
```

### Individual prediction

#### Highest Error {.tabset}

##### 1

```{r}
visualize_specific_prediction(res_lgb)
```

##### 2

```{r}
visualize_specific_prediction(res_lgb, "C1056", "AS27133")
```

##### 3

```{r}
visualize_specific_prediction(res_lgb, "C5015", "AS46000")
```

#### Lowest Error {.tabset}

##### 1

```{r}
visualize_specific_prediction(res_lgb, "C1077", "AS27133")
```

##### 2

```{r}
visualize_specific_prediction(rest_lgb, "C1078", "AS27133")
```

##### 3

```{r}
visualize_specific_prediction(res_lgb, "C1086", "AS27133")
```

## Ensemble

### CV Correlation

```{r}
summary_res <- res_lgb %>% 
  bind_rows(res_lgb_all,
            res_lgb_all_rmse,
            res_lgb_iv,
            res) %>% 
  group_by(method, site_code, product_code, block) %>% 
  summarise(mae = mean(ae))
summary_res %>% 
  spread(method, mae) %>% 
  select(-block) %>% 
  ggcorr(label = TRUE, label_round = 2)
```

```{r}
summary_res_spread %>% 
  group_by(block) %>% 
  summarise_if(is.numeric, mean)
```

### Best Model Selection

Let's combine the model! Using best model selection first!

```{r}
best_selection <- summary_res %>% 
  arrange(site_code, product_code, mae) %>% 
  group_by(site_code, product_code, block) %>% 
  mutate(r = row_number()) %>% 
  filter(r == 1) %>% 
  select(-r) %>% 
  ungroup()
best_selection %>% 
  group_by(block) %>% 
  summarise(mae_mean = mean(mae)) %>% 
  ungroup()
```

It's superb! We can get MAE 7.xx using best selection method. Dramatic! Let's see which model are the best?

```{r}
best_selection %>% 
  count(block, method) %>% 
  group_by(block) %>% 
  mutate(n_all = sum(n),
         p = n / sum(n)) %>% 
  select(-n) %>% 
  spread(method, p)
```

My mind blowns when 50% of the data use Naive! Super crazy! Let's do best model selection between LGB + Naive only

```{r}
best_selection <- summary_res %>% 
  filter(method %in% c("LGB", "Naive")) %>% 
  arrange(site_code, product_code, mae) %>% 
  group_by(site_code, product_code, block) %>% 
  mutate(r = row_number()) %>% 
  filter(r == 1) %>% 
  select(-r) %>% 
  ungroup()
best_selection %>% 
  group_by(block) %>% 
  summarise(mae_mean = mean(mae)) %>% 
  ungroup()
```
 
Quite good, we can reach 8.xx with help from Naive!
 
```{r}
best_selection %>% 
  count(block, method) %>% 
  group_by(block) %>% 
  mutate(n_all = sum(n),
         p = n / sum(n)) %>% 
  select(-n) %>% 
  spread(method, p)
```
 
Kaboom! 60% are using Naive :))

## MAE (Overall)

```{r}
res_all <- res %>% 
  filter(cv == "res_cv1") %>% 
  transmute(site_code,
            product_code,
            cv,
            method,
            y_test = map(res, pluck, "y_test"),
            y_test_pred = map(res, pluck, "y_test_pred")) %>%
  unnest()
res_all %>% 
  filter(!is.na(y_test)) %>% 
  mutate(ae = abs(y_test - y_test_pred)) %>% 
  group_by(method) %>% 
  summarise(n = n(),
            mae = mean(ae)) %>% 
  ungroup() %>% 
  arrange(mae)
```

## MASE Calculation

- 970 time series which are eligible, for test data
- 969 time series which are eligible, for CV-1

```{r}
summary_res %>% 
  filter(block == 43) %>% 
  left_join(summary_diff) %>% 
  mutate(mase = mae / val_diff_cv_43,
         mase = replace_na(mase, 0),
         mase = ifelse(is.infinite(mase), 0, mase)) %>% 
  group_by(method) %>% 
  summarise(mase_mean = mean(mase),
            mase_sd = sd(mase)) %>% 
  ungroup() %>% 
  arrange(mase_mean)
```

```{r}
summary_res %>% 
  bind_rows(
    bind_rows(
      mutate(res_lgb_iv, method = "LGB-i"),
      mutate(res_lgb_all, method = "LGB-ia"),
      mutate(res_lgb_all_rmse, method = "LGB-iar")
    ) %>% 
      group_by(method, site_code, product_code, block) %>% 
      summarise(mae = mean(ae))
  ) %>% 
  filter(block == 43) %>% 
  left_join(summary_diff) %>% 
  mutate(mase = mae / val_diff_test,
         mase = replace_na(mase, 0),
         mase = ifelse(is.infinite(mase), 0, mase)) %>% 
  group_by(method) %>% 
  summarise(mase_mean = mean(mase),
            mase_sd = sd(mase)) %>% 
  ungroup() %>% 
  arrange(mase_mean) %>% 
  mutate(improvement = -1*(mase_mean/1-1) )
```

